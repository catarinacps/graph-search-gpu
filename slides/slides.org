# -*- org-export-babel-evaluate: nil -*-
# -*- coding: utf-8 -*-
# -*- mode: org -*-
#+startup: beamer

#+beamer_header: \title[Trabalho Prático 2]{Percorrimento e Processamento de Grafos em GPU}
#+subtitle: /Arquiteturas Avançadas - INF01191/
#+beamer_header: \author[Henrique Silva]{Henrique Corrêa Pereira da Silva\\Lucas Mello Schnorr (advisor)}
#+email: hcpsilva@inf.ufrgs.br
#+beamer_header: \institute{Instituto de Informática - UFRGS}
#+date:

#+latex_class: beamer
#+latex_class_options: [serif,11pt]
#+beamer_theme: UFRGS
#+options: author:t title:nil H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+language: pt-br
#+tags: noexport(n) ignore(i)
#+export_exclude_tags: noexport
#+export_select_tags: export
#+latex_header: \usepackage{microtype}
#+latex_header: \usepackage{mathtools}
#+latex_header: \usepackage{palatino}
#+latex_header: \usepackage{amssymb}
#+latex_header: \usepackage{csquotes}
#+latex_header: \usepackage{tikz}
#+latex_header: \usepackage[absolute, overlay]{textpos}
#+latex_header: \setlength{\TPHorizModule}{\paperwidth} % Textpos units
#+latex_header: \setlength{\TPVertModule}{\paperwidth} % Textpos units
#+latex_header: \usetikzlibrary{overlay-beamer-styles}  % Overlay effects for TikZ
#+latex_header: \usemintedstyle{manni}

* Notas e comentários                                              :noexport:

Então, pensei em deixar uma introdução direto ao ponto e polêmica, pra chamar
atenção mesmo. Nela, falar de como isso é uma area de pesquisa ativa e os
principais problemas ou diferentes maneiras existentes de abordar o
problema. Quero falar sobre como o ambiente não é trivial de se iniciar e que o
know-how mínimo pra trabalhar nisso é considerável pra graduação. E xingar o
código que nos foi passado.

Depois disso, mostrar os kernels (parte importante). Também mostrar interface
porque ficou bonita.

Metodologia de experimentação e fatores analisados, fora os parametros
experimentais.

Graficos, eixos juntos e no 0, mostrar média e erro padrão.

Conclusão, area de trabalho muito importante e interessante, porém não
trivial. Citar também como uma implementação naive deu ganhos
consideráveis. Colocar no fim a bibliografia.

* Preâmbulo                                                 :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Context

\vfill

In the last few years, we saw the continuation of a decades long trend:
ever-growing *parallelism* in search of performance

\pause \vfill

Also we saw that... \pause
- the hardware naturally specialized over time \pause
- buying highly performant systems became very expensive \pause
- more common systems configurations became hard to extract their full potential

\pause \vfill

Applications running on them can no longer rely on homogeneous hardware if they
seek /high performance/. teste! \cite{shi2018survey}

*** Agenda
:PROPERTIES:
:BEAMER_OPT: plain, noframenumbering
:END:

\tableofcontents

* Introdução
*** Agenda
:PROPERTIES:
:BEAMER_OPT: plain, noframenumbering
:END:

\tableofcontents[currentsubsection, sectionstyle=show/shaded]

*** Implementations

\vfill

Most popular implementations seek to alleviate the burden of programmers

\vfill \pause

Of those implementations the most popular are: \pause

- OpenMP
- OpenMPI
- OpenACC
- etc..

\vfill \pause

**** Attention!

If only utilizing the previously cited APIs, the domain decomposition is
normally fixed to the number of resources \pause *you'll be victim to dynamic
load imbalances*

* Metodologia

** Implementações realizadas

*** Agenda
:PROPERTIES:
:BEAMER_OPT: plain, noframenumbering
:END:

\tableofcontents[currentsubsection, sectionstyle=show/shaded]

*** Objeto de estudo

\vfill

A simple vector accumulation

\vfill \pause

#+attr_latex: :width 8.3cm
[[./images/impl.pdf]]

*** Example kernel

\vfill

#+attr_latex: :options fontsize=\scriptsize
#+begin_src c :tangle no
void reduc_sum(void** buffers, void* cl_arg)
{
    ullint* vec_input = (ullint*)STARPU_VECTOR_GET_PTR(buffers[0]);
    ullint* output = (ullint*)STARPU_VARIABLE_GET_PTR(buffers[1]);
    uint nx_input = STARPU_VECTOR_GET_NX(buffers[0]);

    double t0 = get_time();

    // do the job
    for (uint i = 0; i < nx_input; i++)
        *output += vec_input[i];

    double t1 = get_time();

    V_PRINTF("SUM = %d\n"
             "Task finished work with elapsed time %f\n",
        *output, t1 - t0);
}
#+end_src

** Experimental validation

*** Agenda
:PROPERTIES:
:BEAMER_OPT: plain, noframenumbering
:END:

\tableofcontents[currentsubsection, sectionstyle=show/shaded]

*** Methodological approach

\vfill

A full factorial, randomly ordered experiment design

\vfill \pause

Parameters:
- /Vector size/: =7*10^7, 3*10^8 and 1.1*10^9=
- /Number of blocks/: =7000, 25000 and 82000=
- /Reduction factor/: =2, 10 and 1000=

* Results

** Visualizations

*** Agenda
:PROPERTIES:
:BEAMER_OPT: plain, noframenumbering
:END:

\tableofcontents[currentsubsection, sectionstyle=show/shaded]

*** StarPU

\vfill

#+attr_latex: :height 8cm
[[./images/all_parameters.png]]

*** Combined graph

\vfill

#+attr_latex: :height 8cm
[[./images/combined.png]]

** Conclusions

*** Agenda
:PROPERTIES:
:BEAMER_OPT: plain, noframenumbering
:END:

\tableofcontents[currentsubsection, sectionstyle=show/shaded]

*** Feasibility

\vfill

Even with a simple implementation, we have shown that *StarPU* is a very capable
API

\vfill \pause

Furthermore, we can aggregate the other APIs into our computation kernel \pause

- OpenMP :: therefore, utilizing /parallel tasks/
- OpenMPI :: distribute the execution graph across a whole cluster

* Perguntas                                                 :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

\setbeamercolor{background canvas}{bg = ufrgsgray}
\title{Perguntas?}

*** Obrigado                                                  :B_fullframe:
:PROPERTIES:
:BEAMER_OPT: b, plain, noframenumbering
:BEAMER_env: fullframe
:END:

\titlepage
\vspace*{1.3em}

* Bibliografia                                              :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

\setbeamercolor{background canvas}{bg = white}

*** Bibliografia

\bibliographystyle{apalike}
\scriptsize
\bibliography{refs}

* BibTeX                                                           :noexport:

#+begin_src bib :tangle refs.bib
@article{shi2018survey,
 author = {Shi, Xuanhua and Zheng, Zhigao and Zhou, Yongluan and Jin, Hai and He, Ligang and Liu, Bo and Hua, Qiang-Sheng},
 title = {Graph Processing on GPUs: A Survey},
 journal = {ACM Comput. Surv.},
 issue_date = {January 2018},
 volume = {50},
 number = {6},
 month = jan,
 year = {2018},
 issn = {0360-0300},
 pages = {81:1--81:35},
 articleno = {81},
 numpages = {35},
 url = {http://doi.acm.org/10.1145/3128571},
 doi = {10.1145/3128571},
 acmid = {3128571},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {BSP model, GAS model, GPU, Graph processing, graph datasets, parallelism},
}

@article{merrill2015traversal,
 author = {Merrill, Duane and Garland, Michael and Grimshaw, Andrew},
 title = {High-Performance and Scalable GPU Graph Traversal},
 journal = {ACM Trans. Parallel Comput.},
 issue_date = {January 2015},
 volume = {1},
 number = {2},
 month = feb,
 year = {2015},
 issn = {2329-4949},
 pages = {14:1--14:30},
 articleno = {14},
 numpages = {30},
 url = {http://doi.acm.org/10.1145/2717511},
 doi = {10.1145/2717511},
 acmid = {2717511},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Breadth-first search, GPU, graph algorithms, graph traversal, parallel algorithms, prefix sum, sparse graphs},
}
#+end_src
